{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyL9dP53WjQBpN1ZKX2pux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SREYAKUKUTAPU/Pyspark/blob/main/CreateDataFrame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bpe467yAJo4B"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.master(\"local\").appName(\"dataframe\").getOrCreate()"
      ],
      "metadata": {
        "id": "IrJGiXLBK1bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(spark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "HjnV1EIDLdpd",
        "outputId": "59d51689-a90d-4589-d96f-1c9bdcd1f36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.session.SparkSession"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.session.SparkSession</b><br/>def __init__(sparkContext: SparkContext, jsparkSession: Optional[JavaObject]=None, options: Dict[str, Any]={})</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/session.py</a>The entry point to programming Spark with the Dataset and DataFrame API.\n",
              "\n",
              "A SparkSession can be used to create :class:`DataFrame`, register :class:`DataFrame` as\n",
              "tables, execute SQL over tables, cache tables, and read parquet files.\n",
              "To create a :class:`SparkSession`, use the following builder pattern:\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              ".. autoattribute:: builder\n",
              "   :annotation:\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Create a Spark session.\n",
              "\n",
              "&gt;&gt;&gt; spark = (\n",
              "...     SparkSession.builder\n",
              "...         .master(&quot;local&quot;)\n",
              "...         .appName(&quot;Word Count&quot;)\n",
              "...         .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)\n",
              "...         .getOrCreate()\n",
              "... )\n",
              "\n",
              "Create a Spark session with Spark Connect.\n",
              "\n",
              "&gt;&gt;&gt; spark = (\n",
              "...     SparkSession.builder\n",
              "...         .remote(&quot;sc://localhost&quot;)\n",
              "...         .appName(&quot;Word Count&quot;)\n",
              "...         .config(&quot;spark.some.config.option&quot;, &quot;some-value&quot;)\n",
              "...         .getOrCreate()\n",
              "... )  # doctest: +SKIP</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 166);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'Sreya'),(2,'Minny')]\n",
        "#schema=['id','name']\n",
        "schema=StructType([StructField(name='id',dataType=IntegerType()),StructField(name='name',dataType=StringType())])\n",
        "\n",
        "df=spark.createDataFrame(data,schema)"
      ],
      "metadata": {
        "id": "NZQKRt4ULpMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df.printSchema()\n",
        "type(schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "CO7dsARaNYHF",
        "outputId": "437caad8-355c-49ee-a7ca-1609c4c0f414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Sreya|\n",
            "|  2|Minny|\n",
            "+---+-----+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.types.StructType"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.types.StructType</b><br/>def __init__(fields: Optional[List[StructField]]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/types.py</a>Struct type, consisting of a list of :class:`StructField`.\n",
              "\n",
              "This is the data type representing a :class:`Row`.\n",
              "\n",
              "Iterating a :class:`StructType` will iterate over its :class:`StructField`\\s.\n",
              "A contained :class:`StructField` can be accessed by its name or position.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from pyspark.sql.types import *\n",
              "&gt;&gt;&gt; struct1 = StructType([StructField(&quot;f1&quot;, StringType(), True)])\n",
              "&gt;&gt;&gt; struct1[&quot;f1&quot;]\n",
              "StructField(&#x27;f1&#x27;, StringType(), True)\n",
              "&gt;&gt;&gt; struct1[0]\n",
              "StructField(&#x27;f1&#x27;, StringType(), True)\n",
              "\n",
              "&gt;&gt;&gt; struct1 = StructType([StructField(&quot;f1&quot;, StringType(), True)])\n",
              "&gt;&gt;&gt; struct2 = StructType([StructField(&quot;f1&quot;, StringType(), True)])\n",
              "&gt;&gt;&gt; struct1 == struct2\n",
              "True\n",
              "&gt;&gt;&gt; struct1 = StructType([StructField(&quot;f1&quot;, CharType(10), True)])\n",
              "&gt;&gt;&gt; struct2 = StructType([StructField(&quot;f1&quot;, CharType(10), True)])\n",
              "&gt;&gt;&gt; struct1 == struct2\n",
              "True\n",
              "&gt;&gt;&gt; struct1 = StructType([StructField(&quot;f1&quot;, VarcharType(10), True)])\n",
              "&gt;&gt;&gt; struct2 = StructType([StructField(&quot;f1&quot;, VarcharType(10), True)])\n",
              "&gt;&gt;&gt; struct1 == struct2\n",
              "True\n",
              "&gt;&gt;&gt; struct1 = StructType([StructField(&quot;f1&quot;, StringType(), True)])\n",
              "&gt;&gt;&gt; struct2 = StructType([StructField(&quot;f1&quot;, StringType(), True),\n",
              "...     StructField(&quot;f2&quot;, IntegerType(), False)])\n",
              "&gt;&gt;&gt; struct1 == struct2\n",
              "False\n",
              "\n",
              "The below example demonstrates how to create a DataFrame based on a struct created\n",
              "using class:`StructType` and class:`StructField`:\n",
              "\n",
              "&gt;&gt;&gt; data = [(&quot;Alice&quot;, [&quot;Java&quot;, &quot;Scala&quot;]), (&quot;Bob&quot;, [&quot;Python&quot;, &quot;Scala&quot;])]\n",
              "&gt;&gt;&gt; schema = StructType([\n",
              "...     StructField(&quot;name&quot;, StringType()),\n",
              "...     StructField(&quot;languagesSkills&quot;, ArrayType(StringType())),\n",
              "... ])\n",
              "&gt;&gt;&gt; df = spark.createDataFrame(data=data, schema=schema)\n",
              "&gt;&gt;&gt; df.printSchema()\n",
              "root\n",
              " |-- name: string (nullable = true)\n",
              " |-- languagesSkills: array (nullable = true)\n",
              " |    |-- element: string (containsNull = true)\n",
              "&gt;&gt;&gt; df.show()\n",
              "+-----+---------------+\n",
              "| name|languagesSkills|\n",
              "+-----+---------------+\n",
              "|Alice|  [Java, Scala]|\n",
              "|  Bob|[Python, Scala]|\n",
              "+-----+---------------+</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 729);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[{'id':1,'name':'Sreya'},{'id':2,'name':'Minny'}]\n",
        "df=spark.createDataFrame(data=data)\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyN7wgQfQNyY",
        "outputId": "7ccb79fe-1013-409c-bbf6-c300371d9918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+\n",
            "| id| name|\n",
            "+---+-----+\n",
            "|  1|Sreya|\n",
            "|  2|Minny|\n",
            "+---+-----+\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}